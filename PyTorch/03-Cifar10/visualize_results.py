# CIFAR-10è¨“ç·´çµæœå¯è¦–åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
import torch
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np
import os
from tensorboard.backend.event_processing import event_accumulator

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆWindowsç’°å¢ƒï¼‰
plt.rcParams['font.sans-serif'] = ['MS Gothic', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# CIFAR-10ã‚¯ãƒ©ã‚¹å
classes = ('é£›è¡Œæ©Ÿ', 'è‡ªå‹•è»Š', 'é³¥', 'çŒ«', 'é¹¿',
           'çŠ¬', 'ã‚«ã‚¨ãƒ«', 'é¦¬', 'èˆ¹', 'ãƒˆãƒ©ãƒƒã‚¯')

# resultsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
os.makedirs("results", exist_ok=True)

print("=" * 60)
print("CIFAR-10 è¨“ç·´çµæœå¯è¦–åŒ–")
print("=" * 60)

# ========================================
# 1. TensorBoardãƒ­ã‚°ã‹ã‚‰è¨“ç·´å±¥æ­´ã‚’èª­ã¿è¾¼ã‚€
# ========================================
print("\n[1/3] TensorBoardãƒ­ã‚°ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")

def read_tensorboard_logs(log_dir):
    """TensorBoardãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¨“ç·´å±¥æ­´ã‚’æŠ½å‡º"""
    try:
        # ã‚¤ãƒ™ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        event_files = []
        for root, dirs, files in os.walk(log_dir):
            for file in files:
                if 'events.out.tfevents' in file:
                    event_files.append(os.path.join(root, file))

        if not event_files:
            print(f"âš ï¸  {log_dir}ã«ã‚¤ãƒ™ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return None

        # æœ€åˆã®ã‚¤ãƒ™ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        ea = event_accumulator.EventAccumulator(event_files[0])
        ea.Reload()

        history = {}

        # ã‚¹ã‚«ãƒ©ãƒ¼å€¤ã‚’å–å¾—
        for tag in ea.Tags()['scalars']:
            events = ea.Scalars(tag)
            history[tag] = {
                'steps': [e.step for e in events],
                'values': [e.value for e in events]
            }

        return history
    except Exception as e:
        print(f"âš ï¸  ãƒ­ã‚°èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None

# ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¤œç´¢
log_dirs = []
if os.path.exists("logs"):
    for item in os.listdir("logs"):
        item_path = os.path.join("logs", item)
        if os.path.isdir(item_path):
            log_dirs.append(item_path)

if log_dirs:
    print(f"âœ… {len(log_dirs)}å€‹ã®ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç™ºè¦‹")

    # å„ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨“ç·´å±¥æ­´ã‚’å¯è¦–åŒ–
    plt.figure(figsize=(15, 5))

    for idx, log_dir in enumerate(log_dirs):
        model_name = os.path.basename(log_dir)
        print(f"   å‡¦ç†ä¸­: {model_name}")
        history = read_tensorboard_logs(log_dir)

        if history and 'test loss' in history:
            plt.subplot(1, 2, 1)
            plt.plot(history['test loss']['steps'],
                    history['test loss']['values'],
                    label=model_name, linewidth=2)

        if history and 'test correct' in history:
            plt.subplot(1, 2, 2)
            plt.plot(history['test correct']['steps'],
                    history['test correct']['values'],
                    label=model_name, linewidth=2)

    plt.subplot(1, 2, 1)
    plt.title('ãƒ†ã‚¹ãƒˆæå¤±ã®æ¨ç§»', fontsize=14, fontweight='bold')
    plt.xlabel('Epoch', fontsize=12)
    plt.ylabel('Loss', fontsize=12)
    plt.legend()
    plt.grid(True, alpha=0.3)

    plt.subplot(1, 2, 2)
    plt.title('ãƒ†ã‚¹ãƒˆç²¾åº¦ã®æ¨ç§»', fontsize=14, fontweight='bold')
    plt.xlabel('Epoch', fontsize=12)
    plt.ylabel('Accuracy (%)', fontsize=12)
    plt.legend()
    plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig('results/training_curves.png', dpi=150, bbox_inches='tight')
    print("âœ… è¨“ç·´æ›²ç·šã‚’ä¿å­˜ã—ã¾ã—ãŸ: results/training_curves.png")
    plt.close()
else:
    print("âš ï¸  logsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

# ========================================
# 2. äºˆæ¸¬çµæœã®å¯è¦–åŒ–
# ========================================
print("\n[2/3] äºˆæ¸¬çµæœã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™...")

try:
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

    testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                          download=True, transform=transform)
    testloader = torch.utils.data.DataLoader(testset, batch_size=4,
                                            shuffle=True, num_workers=0)

    # æœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€
    # ã¾ãšã€åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’ç¢ºèª
    model_files = [f for f in os.listdir('models') if f.endswith('.pth')]
    if model_files:
        # æœ€ã‚‚å¤§ãã„ã‚¨ãƒãƒƒã‚¯ç•ªå·ã®ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ
        latest_model = sorted(model_files, key=lambda x: int(x.replace('.pth', '')))[-1]
        model_path = os.path.join('models', latest_model)

        # ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«ã¯ã€ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®å®šç¾©ãŒå¿…è¦
        # ã“ã“ã§ã¯ã€pre_resnetã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ã¨ä»®å®š
        from pre_resnet import pytorch_resnet18

        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model = pytorch_resnet18().to(device)
        model.load_state_dict(torch.load(model_path, map_location=device))
        model.eval()

        print(f"âœ… ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {model_path}")

        # ãƒ©ãƒ³ãƒ€ãƒ ãªç”»åƒã§äºˆæ¸¬
        dataiter = iter(testloader)

        # è¤‡æ•°ãƒãƒƒãƒã‚’å–å¾—ã—ã¦20æšã®ç”»åƒã‚’ç”¨æ„
        images_list = []
        labels_list = []
        for _ in range(5):
            imgs, lbls = next(dataiter)
            images_list.append(imgs)
            labels_list.append(lbls)

        images = torch.cat(images_list, dim=0)[:20]
        labels = torch.cat(labels_list, dim=0)[:20]

        # äºˆæ¸¬
        with torch.no_grad():
            images = images.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)

        # å¯è¦–åŒ–
        fig, axes = plt.subplots(4, 5, figsize=(15, 12))
        fig.suptitle('CIFAR-10ç”»åƒåˆ†é¡ - äºˆæ¸¬çµæœ', fontsize=16, fontweight='bold')

        for idx, ax in enumerate(axes.flat):
            # ç”»åƒã‚’æ­£è¦åŒ–è§£é™¤
            img = images[idx].cpu() / 2 + 0.5
            img = img.permute(1, 2, 0).numpy()
            img = np.clip(img, 0, 1)

            ax.imshow(img)

            true_label = labels[idx].item()
            pred_label = predicted[idx].item()

            # ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆæ­£è§£ã‹ä¸æ­£è§£ã‹ã§è‰²ã‚’å¤‰ãˆã‚‹ï¼‰
            if pred_label == true_label:
                color = 'green'
                status = 'âœ“'
            else:
                color = 'red'
                status = 'âœ—'

            ax.set_title(f'{status} äºˆæ¸¬: {classes[pred_label]}\næ­£è§£: {classes[true_label]}',
                        fontsize=10, color=color, fontweight='bold')
            ax.axis('off')

        plt.tight_layout()
        plt.savefig('results/predictions.png', dpi=150, bbox_inches='tight')
        print("âœ… äºˆæ¸¬çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: results/predictions.png")
        plt.close()

        # ========================================
        # 3. ã‚¯ãƒ©ã‚¹åˆ¥ç²¾åº¦ã®åˆ†æ
        # ========================================
        print("\n[3/3] ã‚¯ãƒ©ã‚¹åˆ¥ç²¾åº¦ã‚’åˆ†æã—ã¦ã„ã¾ã™...")

        class_correct = [0] * 10
        class_total = [0] * 10

        with torch.no_grad():
            for data in testloader:
                images, labels = data
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                _, predicted = torch.max(outputs, 1)

                for i in range(len(labels)):
                    label = labels[i].item()
                    class_total[label] += 1
                    if predicted[i] == label:
                        class_correct[label] += 1

        # ã‚¯ãƒ©ã‚¹åˆ¥ç²¾åº¦ã‚’å¯è¦–åŒ–
        accuracies = [100 * class_correct[i] / class_total[i] if class_total[i] > 0 else 0
                     for i in range(10)]

        plt.figure(figsize=(12, 6))
        bars = plt.bar(range(10), accuracies, color='skyblue', edgecolor='navy')

        # æœ€é«˜ç²¾åº¦ã¨æœ€ä½ç²¾åº¦ã®ãƒãƒ¼ã‚’è‰²åˆ†ã‘
        max_idx = np.argmax(accuracies)
        min_idx = np.argmin(accuracies)
        bars[max_idx].set_color('green')
        bars[min_idx].set_color('red')

        plt.xlabel('ã‚¯ãƒ©ã‚¹', fontsize=12)
        plt.ylabel('ç²¾åº¦ (%)', fontsize=12)
        plt.title('CIFAR-10 ã‚¯ãƒ©ã‚¹åˆ¥ç²¾åº¦', fontsize=14, fontweight='bold')
        plt.xticks(range(10), classes, rotation=45, ha='right')
        plt.ylim([0, 100])
        plt.grid(True, alpha=0.3, axis='y')

        # ç²¾åº¦å€¤ã‚’è¡¨ç¤º
        for i, v in enumerate(accuracies):
            plt.text(i, v + 2, f'{v:.1f}%', ha='center', fontsize=10)

        plt.tight_layout()
        plt.savefig('results/class_accuracy.png', dpi=150, bbox_inches='tight')
        print("âœ… ã‚¯ãƒ©ã‚¹åˆ¥ç²¾åº¦ã‚’ä¿å­˜ã—ã¾ã—ãŸ: results/class_accuracy.png")
        plt.close()

        # å…¨ä½“ç²¾åº¦ã‚’è¨ˆç®—
        overall_accuracy = 100 * sum(class_correct) / sum(class_total)
        print(f"\nğŸ“Š å…¨ä½“ãƒ†ã‚¹ãƒˆç²¾åº¦: {overall_accuracy:.2f}%")

    else:
        print("âš ï¸  è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

except FileNotFoundError:
    print("âš ï¸  å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
except Exception as e:
    print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    import traceback
    traceback.print_exc()

print("\n" + "=" * 60)
print("âœ… å¯è¦–åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
print("=" * 60)
print("\nğŸ“Š ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:")
if os.path.exists('results/training_curves.png'):
    print("  - results/training_curves.png    : è¨“ç·´æ›²ç·š")
if os.path.exists('results/predictions.png'):
    print("  - results/predictions.png        : äºˆæ¸¬çµæœ")
if os.path.exists('results/class_accuracy.png'):
    print("  - results/class_accuracy.png     : ã‚¯ãƒ©ã‚¹åˆ¥ç²¾åº¦")
print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: ã“ã‚Œã‚‰ã®ç”»åƒã‚’READMEã«è¿½åŠ ã—ã¾ã—ã‚‡ã†ï¼")
